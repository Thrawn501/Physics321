TITLE: PHY321: Conservative Forces, Examples and start Harmonic Oscillations
AUTHOR: "Morten Hjorth-Jensen":"http://mhjgit.github.io/info/doc/web/" {copyright, 1999-present|CC BY-NC} at Department of Physics and Astronomy and Facility for Rare Ion Beams (FRIB), Michigan State University, USA & Department of Physics, University of Oslo, Norway
DATE: today


!split
=====   Aims and Overarching Motivation =====

=== Monday ===

Short repetition from last week about conservative forces. Discussion
of conditions for conservative forces and the Earth-Sun gravitional
force example.  _Reading suggestion_: Taylor sections 4.3, 4.4 and 4.8.

=== Wednesday ===

Potential curves and discussion of the Earth-Sun example, analytical and numerical considerations.
_Reading suggestions_: Taylor section 4.6, 4.8 and 4.9.

===  Friday ===
Earth-Sun,  conservative forces and potential energy.
_Reading suggestion_: Taylor sections 4.8 and 4.9.

If we get time, we start with harmonic oscillations and Hooke's law. _Reading suggestion_: Taylor section 5.1.


!split
===== One Figure to Rule All Forces (thx to Julie) =====

FIGURE: [figslides/ClassicalMechanicsJulie.png, width=600 frac=0.8]  


!split
===== Repetition from last week: Work, Energy, Momentum and Conservation laws =====

Energy conservation is most convenient as a strategy for addressing
problems where time does not appear. For example, a particle goes
from position $x_0$ with speed $v_0$, to position $x_f$; what is its
new speed? However, it can also be applied to problems where time
does appear, such as in solving for the trajectory $x(t)$, or
equivalently $t(x)$.




!split
===== Energy Conservation =====
Energy is conserved in the case where the potential energy, $V(\bm{r})$, depends only on position, and not on time. The force is determined by $V$,
!bt
\begin{equation}
\bm{F}(\bm{r})=-\bm{\nabla} V(\bm{r}).
\end{equation}
!et




!split
===== Conservative forces =====

We say a force is conservative if it satisfies the following conditions:
o The force $\bm{F}$ acting on an object only depends on the position $\bm{r}$, that is $\bm{F}=\bm{F}(\bm{r})$.
o For any two points $\bm{r}_1$ and $\bm{r}_2$, the work done by the force $\bm{F}$ on the displacement between these two points is independent of the path taken.
o Finally, the _curl_ of the force is zero $\bm{\nabla}\times\bm{F}=0$.


!split
===== Forces and Potentials =====

The energy $E$ of a given system is defined as the sum of kinetic and potential energies,
!bt
\[
E=K+V(\bm{r}).
\]
!et

We define the potential energy at a point $\bm{r}$ as the negative work done from a starting point $\bm{r}_0$ to a final point $\bm{r}$ 

!bt
\[
V(\bm{r})=-W(\bm{r}_0\rightarrow\bm{r})= -\int_{\bm{r}_0}^{\bm{r}}d\bm{r}'\bm{F}(\bm{r}').
\]
!et
If the potential depends on the path taken between these two points there is no unique potential.


!split
===== Example (relevant for homework 5) =====

We study a classical electron which moves in the $x$-direction along a surface. The force from the surface is
!bt
\[
\bm{F}(x)=-F_0\sin{(\frac{2\pi x}{b})}\bm{e}_1.
\]
!et
The constant $b$ represents the distance between atoms at the surface of the material, $F_0$ is a constant and $x$ is the position of the electron.

This is indeed a conservative force since it depends only on position
and its _curl_ is zero, that is $-\bm{\nabla}\times \bm{F}=0$. This means that energy is conserved and the
integral over the work done by the force is independent of the path
taken. 

!split
===== Example Continues =====


Using the work-energy theorem we can find the work $W$ done when
moving an electron from a position $x_0$ to a final position $x$
through the integral

!bt
\[
W=\int_{x_0}^x \bm{F}(x')dx' =  -\int_{x_0}^x F_0\sin{(\frac{2\pi x'}{b})} dx',
\]
!et
which results in
!bt
\[
W=\frac{F_0b}{2\pi}\left[\cos{(\frac{2\pi x}{b})}-\cos{(\frac{2\pi x_0}{b})}\right].
\]
!et
Since this is related to the change in kinetic energy we have, with $v_0$ being the initial velocity at a  time $t_0$,
!bt
\[
v  = \pm\sqrt{\frac{2}{m}\frac{F_0b}{2\pi}\left[\cos{(\frac{2\pi x}{b})}-\cos{(\frac{2\pi x_0}{b})}\right]+v_0^2}.
\]
!et

!split
===== The potential energy from this example =====

The potential energy, due to energy conservation is
!bt
\[
V(x)=V(x_0)+\frac{1}{2}mv_0^2-\frac{1}{2}mv^2,
\]
!et
with $v$ given by the velocity from above.

We can now, in order to find a more explicit expression for the
potential energy at a given value $x$, define a zero level value for
the potential. The potential is defined, using the work-energy
theorem, as


!bt
\[
V(x)=V(x_0)+\int_{x_0}^x (-F(x'))dx',
\]
!et

and if you recall the definition of the indefinite integral, we can rewrite this as

!bt
\[
V(x)=\int (-F(x'))dx'+C,
\]
!et

where $C$ is an undefined constant. The force is defined as the
gradient of the potential, and in that case the undefined constant
vanishes. The constant does not affect the force we derive from the
potential.

We have then
!bt
\[
V(x)=V(x_0)-\int_{x_0}^x \bm{F}(x')dx',
\]
!et
which results in
!bt
\[
V(x)=-\frac{F_0b}{2\pi}\left[\cos{(\frac{2\pi x}{b})}-\cos{(\frac{2\pi x_0}{b})}\right]+V(x_0).
\]
!et
We can now define
!bt
\[
-\frac{F_0b}{2\pi}\cos{(\frac{2\pi x_0}{b})}=V(x_0),
\]
!et
which gives 
!bt
\[
V(x)=-\frac{F_0b}{2\pi}\left[\cos{(\frac{2\pi x}{b})}\right].
\]
!et

!split
===== Force and Potential =====

We have defined work as the energy resulting from a net force acting
on an object (or sseveral objects), that is

!bt
\[
W(\bm{r}\rightarrow \bm{r}+d\bm{r})= \bm{F}(\bm{r})d\bm{r}.
\]
!et

If we write out this for each component we have

!bt
\[
W(\bm{r}\rightarrow \bm{r}+d\bm{r})=\bm{F}(\bm{r})d\bm{r}=F_xdx+F_ydy+F_zdz.
\]
!et

The work done from an initial position to a final one defines also the difference in potential energies

!bt
\[
W(\bm{r}\rightarrow \bm{r}+d\bm{r})=-\left[V(\bm{r}+d\bm{r})-V(\bm{r})\right].
\]
!et

!split
=====  Getting to $\bm{F}(\bm{r})=-\bm{\nabla} V(\bm{r})$ =====

We can write out the differences in potential energies as

!bt
\[
V(\bm{r}+d\bm{r})-V(\bm{r})=V(x+dx,y+dy,z+dz)-V(x,y,z)=dV,
\]
!et
and using the expression the differential of a multi-variable function $f(x,y,z)$ 
!bt
\[
df=\frac{\partial f}{\partial x}dx+\frac{\partial f}{\partial y}dy+\frac{\partial f}{\partial z}dz,
\]
!et
we can write the expression for the work done as
!bt
\[
W(\bm{r}\rightarrow \bm{r}+d\bm{r})=-dV=-\left[\frac{\partial V}{\partial x}dx+\frac{\partial V}{\partial y}dy+\frac{\partial V}{\partial z}dz \right].
\]
!et

!split
===== Final expression =====

Comparing the last equation with 
!bt
\[
W(\bm{r}\rightarrow \bm{r}+d\bm{r})=F_xdx+F_ydy+F_zdz,
\]
!et
we have
!bt
\[
F_xdx+F_ydy+F_zdz=-\left[\frac{\partial V}{\partial x}dx+\frac{\partial V}{\partial y}dy+\frac{\partial V}{\partial z}dz \right],
\]
!et

leading to
!bt
\[
F_x=-\frac{\partial V}{\partial x},
\]
!et
and
!bt
\[
F_y=-\frac{\partial V}{\partial y},
\]
!et
and
!bt
\[
F_z=-\frac{\partial V}{\partial z},
\]
!et
or just
!bt
\[
\bm{F}=-\frac{\partial V}{\partial x}\bm{e}_1-\frac{\partial V}{\partial y}\bm{e}_2-\frac{\partial V}{\partial z}\bm{e}_3=-\bm{\nabla}V(\bm{r}).
\]
!et
And this connection is the one we wanted to show.


!split
===== Net Energy  =====

The net energy, $E=V+K$ where $K$ is the kinetic energy, is then conserved,

!bt
\begin{eqnarray}
\frac{d}{dt}(K+V)&=&\frac{d}{dt}\left(\frac{m}{2}(v_x^2+v_y^2+v_z^2)+V(\bm{r})\right)\\
\nonumber
&=&m\left(v_x\frac{dv_x}{dt}+v_y\frac{dv_y}{dt}+v_z\frac{dv_z}{dt}\right)
+\partial_xV\frac{dx}{dt}+\partial_yV\frac{dy}{dt}+\partial_zV\frac{dz}{dt}\\
\nonumber
&=&v_xF_x+v_yF_y+v_zF_z-F_xv_x-F_yv_y-F_zv_z=0.
\end{eqnarray}
!et


!split
===== In Vector Notation  =====

The same proof can be written more compactly with vector notation,

!bt
\begin{eqnarray}
\frac{d}{dt}\left(\frac{m}{2}v^2+V(\bm{r})\right)
&=&m\bm{v}\cdot\dot{\bm{v}}+\bm{\nabla} V(\bm{r})\cdot\dot{\bm{r}}\\
\nonumber
&=&\bm{v}\cdot\bm{F}-\bm{F}\cdot\bm{v}=0.
\end{eqnarray}
!et

Inverting the expression for kinetic energy,
!bt
\begin{equation}
v=\sqrt{2K/m}=\sqrt{2(E-V)/m},
\end{equation}
!et

allows one to solve for the one-dimensional trajectory $x(t)$, by finding $t(x)$,

!bt
\begin{equation}
t=\int_{x_0}^x \frac{dx'}{v(x')}=\int_{x_0}^x\frac{dx'}{\sqrt{2(E-V(x'))/m}}.
\end{equation}
!et

Note this would be much more difficult in higher dimensions, because
you would have to determine which points, $x,y,z$, the particles might
reach in the trajectory, whereas in one dimension you can typically
tell by simply seeing whether the kinetic energy is positive at every
point between the old position and the new position.


!split
===== Harmonic Oscillator Potential =====


Consider a simple harmonic oscillator potential, $V(x)=kx^2/2$, with a particle emitted from $x=0$ with velocity $v_0$. Solve for the trajectory $t(x)$,

!bt
\begin{eqnarray}
t&=&\int_{0}^x \frac{dx'}{\sqrt{2(E-kx^2/2)/m}}\\
\nonumber
&=&\sqrt{m/k}\int_0^x~\frac{dx'}{\sqrt{x_{\rm max}^2-x^{\prime 2}}},~~~x_{\rm max}^2=2E/k.
\end{eqnarray}
!et

Here $E=mv_0^2/2$ and $x_{\rm max}$ is defined as the maximum
displacement before the particle turns around. This integral is done
by the substitution $\sin\theta=x/x_{\rm max}$.

!bt
\begin{eqnarray}
(k/m)^{1/2}t&=&\sin^{-1}(x/x_{\rm max}),\\
\nonumber
x&=&x_{\rm max}\sin\omega t,~~~\omega=\sqrt{k/m}.
\end{eqnarray}
!et


!split
===== The Earth-Sun system =====

We will now venture into a study of a system which is energy
conserving. The aim is to see if we (since it is not possible to solve
the general equations analytically) we can develop stable numerical
algorithms whose results we can trust!

We solve the equations of motion numerically. We will also compute
quantities like the energy numerically.

We start with a simpler case first, the Earth-Sun system  in two dimensions only.  The gravitational force $F_G$ on the earth from the sun is  
!bt
\[
\bm{F}_G=-\frac{GM_{\odot}M_E}{r^3}\bm{r},
\]
!et
where $G$ is the gravitational constant, 
!bt
\[
M_E=6\times 10^{24}\mathrm{Kg},
\]
!et 
the mass of Earth, 
!bt
\[
M_{\odot}=2\times 10^{30}\mathrm{Kg}, 
\]
!et
the mass of the Sun and 
!bt
\[
r=1.5\times 10^{11}\mathrm{m}, 
\]
!et
is the distance between Earth and the Sun. The latter defines what we call an astronomical unit _AU_.


!split
===== The Earth-Sun system, Newton's Laws =====

From Newton's second law we have then for the $x$ direction
!bt
\[
\frac{d^2x}{dt^2}=-\frac{F_{x}}{M_E},
\]
!et
and
!bt
\[
\frac{d^2y}{dt^2}=-\frac{F_{y}}{M_E},
\]
!et 
for the $y$ direction.

Here we will use  that  $x=r\cos{(\theta)}$, $y=r\sin{(\theta)}$ and
!bt
\[
r = \sqrt{x^2+y^2}.
\]
!et 
We can rewrite 
!bt
\[
F_{x}=-\frac{GM_{\odot}M_E}{r^2}\cos{(\theta)}=-\frac{GM_{\odot}M_E}{r^3}x,
\]
!et
and
!bt
\[
F_{y}=-\frac{GM_{\odot}M_E}{r^2}\sin{(\theta)}=-\frac{GM_{\odot}M_E}{r^3}y,
\]
!et 
for the $y$ direction.

!split
===== The Earth-Sun system, rewriting the Equations =====

We can rewrite these two equations
!bt
\[
F_{x}=-\frac{GM_{\odot}M_E}{r^2}\cos{(\theta)}=-\frac{GM_{\odot}M_E}{r^3}x,
\]
!et
and
!bt
\[
F_{y}=-\frac{GM_{\odot}M_E}{r^2}\sin{(\theta)}=-\frac{GM_{\odot}M_E}{r^3}y,
\]
!et 
as four first-order coupled differential equations
!bt
\[
\frac{dv_x}{dt}=-\frac{GM_{\odot}}{r^3}x,
\]
!et
!bt
\[
\frac{dx}{dt}=v_x,
\]
!et
!bt
\[
\frac{dv_y}{dt}=-\frac{GM_{\odot}}{r^3}y,
\]
!et
!bt
\[
\frac{dy}{dt}=v_y.
\]
!et



!split
===== Building a code for the solar system, final coupled equations =====

The four coupled differential equations
!bt
\[
\frac{dv_x}{dt}=-\frac{GM_{\odot}}{r^3}x,
\]
!et
!bt
\[
\frac{dx}{dt}=v_x,
\]
!et
!bt
\[
\frac{dv_y}{dt}=-\frac{GM_{\odot}}{r^3}y,
\]
!et
!bt
\[
\frac{dy}{dt}=v_y,
\]
!et
can be turned into dimensionless equations or we can introduce astronomical units with $1$ AU = $1.5\times 10^{11}$. 

Using the equations from circular motion (with $r =1\mathrm{AU}$) 
!bt
\[
\frac{M_E v^2}{r} = F = \frac{GM_{\odot}M_E}{r^2},
\]
!et 
we have
!bt
\[
GM_{\odot}=v^2r,
\]
!et  
and using that the velocity of Earth (assuming circular motion) is
$v = 2\pi r/\mathrm{yr}=2\pi\mathrm{AU}/\mathrm{yr}$, we have
!bt
\[
GM_{\odot}= v^2r = 4\pi^2 \frac{(\mathrm{AU})^3}{\mathrm{yr}^2}.
\]
!et 



!split
===== Building a code for the solar system, discretized equations =====

The four coupled differential equations can then be discretized using Euler's method as (with step length $h$)
!bt
\[
v_{x,i+1}=v_{x,i}-h\frac{4\pi^2}{r_i^3}x_i,
\]
!et
!bt
\[
x_{i+1}=x_i+hv_{x,i},
\]
!et
!bt
\[
v_{y,i+1}=v_{y,i}-h\frac{4\pi^2}{r_i^3}y_i,
\]
!et
!bt
\[
y_{i+1}=y_i+hv_{y,i},
\]
!et


!split
===== Code Example with Euler's Method =====

The code here implements Euler's method for the Earth-Sun system using a more compact way of representing the vectors. Alternatively, you could have spelled out all the variables $v_x$, $v_y$, $x$ and $y$ as one-dimensional arrays. 

!bc pycod
# Common imports
import numpy as np
import pandas as pd
from math import *
import matplotlib.pyplot as plt
import os

# Where to save the figures and data files
PROJECT_ROOT_DIR = "Results"
FIGURE_ID = "Results/FigureFiles"
DATA_ID = "DataFiles/"

if not os.path.exists(PROJECT_ROOT_DIR):
    os.mkdir(PROJECT_ROOT_DIR)

if not os.path.exists(FIGURE_ID):
    os.makedirs(FIGURE_ID)

if not os.path.exists(DATA_ID):
    os.makedirs(DATA_ID)

def image_path(fig_id):
    return os.path.join(FIGURE_ID, fig_id)

def data_path(dat_id):
    return os.path.join(DATA_ID, dat_id)

def save_fig(fig_id):
    plt.savefig(image_path(fig_id) + ".png", format='png')


DeltaT = 0.001
#set up arrays 
tfinal = 10 # in years
n = ceil(tfinal/DeltaT)
# set up arrays for t, a, v, and x
t = np.zeros(n)
v = np.zeros((n,2))
r = np.zeros((n,2))
# Initial conditions as compact 2-dimensional arrays
r0 = np.array([1.0,0.0])
v0 = np.array([0.0,2*pi])
r[0] = r0
v[0] = v0
Fourpi2 = 4*pi*pi
# Start integrating using Euler's method
for i in range(n-1):
    # Set up the acceleration
    # Here you could have defined your own function for this
    rabs = sqrt(sum(r[i]*r[i]))
    a =  -Fourpi2*r[i]/(rabs**3)
    # update velocity, time and position using Euler's forward method
    v[i+1] = v[i] + DeltaT*a
    r[i+1] = r[i] + DeltaT*v[i]
    t[i+1] = t[i] + DeltaT
# Plot position as function of time    
fig, ax = plt.subplots()
#ax.set_xlim(0, tfinal)
ax.set_ylabel('x[m]')
ax.set_xlabel('y[m]')
ax.plot(r[:,0], r[:,1])
fig.tight_layout()
save_fig("EarthSunEuler")
plt.show()
!ec


!split
===== Problems with Euler's Method =====

We notice here that Euler's method doesn't give a stable orbit. It
means that we cannot trust Euler's method. In a deeper way, as we will
see in homework 5, Euler's method does not conserve energy. It is an
example of an integrator which is not
"symplectic":"https://en.wikipedia.org/wiki/Symplectic_integrator".

Here we present thus two methods, which with simple changes allow us to avoid these pitfalls. The simplest possible extension is the so-called Euler-Cromer method.
The changes we need to make to our code are indeed marginal here.
We need simply to replace
!bc pycod
    r[i+1] = r[i] + DeltaT*v[i]
!ec
in the above code with the velocity at the new time $t_{i+1}$
!bc pycod
    r[i+1] = r[i] + DeltaT*v[i+1]
!ec

By this simple caveat we get stable orbits.
Below we derive the Euler-Cromer method as well as one of the most utlized algorithms for sovling the above type of problems, the so-called Velocity-Verlet method. 

!split
===== Deriving the Euler-Cromer Method =====

Let us repeat Euler's method.
We have a differential equation
!bt
\begin{equation}
y'(t_i)=f(t_i,y_i)   
\end{equation}
!et
and if we truncate at the first derivative, we have from the Taylor expansion
!bt
\begin{equation}
y_{i+1}=y(t_i) + (\Delta t) f(t_i,y_i) + O(\Delta t^2), label{eq:euler}
\end{equation}
!et
which when complemented with $t_{i+1}=t_i+\Delta t$ forms
the algorithm for the well-known Euler method. 
Note that at every step we make an approximation error
of the order of $O(\Delta t^2)$, however the total error is the sum over all
steps $N=(b-a)/(\Delta t)$ for $t\in [a,b]$, yielding thus a global error which goes like
$NO(\Delta t^2)\approx O(\Delta t)$. 

To make Euler's method more precise we can obviously
decrease $\Delta t$ (increase $N$), but this can lead to loss of numerical precision.
Euler's method is not recommended for precision calculation,
although it is handy to use in order to get a first
view on how a solution may look like.

Euler's method is asymmetric in time, since it uses information about the derivative at the beginning
of the time interval. This means that we evaluate the position at $y_1$ using the velocity
at $v_0$. A simple variation is to determine $x_{n+1}$ using the velocity at
$v_{n+1}$, that is (in a slightly more generalized form)
!bt
\begin{equation} 
y_{n+1}=y_{n}+ v_{n+1}+O(\Delta t^2)
\end{equation}
!et
and 
!bt
\begin{equation}
v_{n+1}=v_{n}+(\Delta t) a_{n}+O(\Delta t^2).
\end{equation}
!et
The acceleration $a_n$ is a function of $a_n(y_n, v_n, t_n)$ and needs to be evaluated
as well. This is the Euler-Cromer method.

_Exercise_: go back to the above code with Euler's method and add the Euler-Cromer method. 


!split
===== Deriving the Velocity-Verlet Method =====

Let us stay with $x$ (position) and $v$ (velocity) as the quantities we are interested in.

We have the Taylor expansion for the position given by
!bt
\[
x_{i+1} = x_i+(\Delta t)v_i+\frac{(\Delta t)^2}{2}a_i+O((\Delta t)^3).
\]
!et
The corresponding expansion for the velocity is 
!bt
\[
v_{i+1} = v_i+(\Delta t)a_i+\frac{(\Delta t)^2}{2}v^{(2)}_i+O((\Delta t)^3).
\]
!et
Via Newton's second law we have normally an analytical expression for the derivative of the velocity, namely
!bt
\[
a_i= \frac{d^2 x}{dt^2}\vert_{i}=\frac{d v}{dt}\vert_{i}= \frac{F(x_i,v_i,t_i)}{m}.
\]
!et


If we add to this the corresponding expansion for the derivative of the velocity 
!bt
\[
v^{(1)}_{i+1} = a_{i+1}= a_i+(\Delta t)v^{(2)}_i+O((\Delta t)^2)=a_i+(\Delta t)v^{(2)}_i+O((\Delta t)^2), 
\]
!et
and retain only terms up to the second derivative of the velocity since our error goes as $O(h^3)$, we have
!bt
\[
(\Delta t)v^{(2)}_i\approx a_{i+1}-a_i.
\]
!et
We can then rewrite the Taylor expansion for the velocity as  
!bt
\[
v_{i+1} = v_i+\frac{(\Delta t)}{2}\left( a_{i+1}+a_{i}\right)+O((\Delta t)^3).
\]
!et




!split
===== The velocity Verlet method =====

Our final equations for the position and the velocity become then 
!bt
\[
x_{i+1} = x_i+(\Delta t)v_i+\frac{(\Delta t)^2}{2}a_{i}+O((\Delta t)^3),
\]
!et
and
!bt
\[
v_{i+1} = v_i+\frac{(\Delta t)}{2}\left(a_{i+1}+a_{i}\right)+O((\Delta t)^3). 
\]
!et
Note well that the term $a_{i+1}$ depends on the position at $x_{i+1}$. This means that you need to calculate 
the position at the updated time $t_{i+1}$ before the computing the next velocity.  Note also that the derivative of the velocity at the time
$t_i$ used in the updating of the position can be reused in the calculation of the velocity update as well. 


!split
===== Adding the Velocity-Verlet Method =====

We can now easily add the Verlet method to our original code as
!bc pycod
DeltaT = 0.01
#set up arrays 
tfinal = 10
n = ceil(tfinal/DeltaT)
# set up arrays for t, a, v, and x
t = np.zeros(n)
v = np.zeros((n,2))
r = np.zeros((n,2))
# Initial conditions as compact 2-dimensional arrays
r0 = np.array([1.0,0.0])
v0 = np.array([0.0,2*pi])
r[0] = r0
v[0] = v0
Fourpi2 = 4*pi*pi
# Start integrating using the Velocity-Verlet  method
for i in range(n-1):
    # Set up forces, air resistance FD, note now that we need the norm of the vecto
    # Here you could have defined your own function for this
    rabs = sqrt(sum(r[i]*r[i]))
    a =  -Fourpi2*r[i]/(rabs**3)
    # update velocity, time and position using the Velocity-Verlet method
    r[i+1] = r[i] + DeltaT*v[i]+0.5*(DeltaT**2)*a
    rabs = sqrt(sum(r[i+1]*r[i+1]))
    anew = -4*(pi**2)*r[i+1]/(rabs**3)
    v[i+1] = v[i] + 0.5*DeltaT*(a+anew)
    t[i+1] = t[i] + DeltaT
# Plot position as function of time    
fig, ax = plt.subplots()
ax.set_ylabel('x[m]')
ax.set_xlabel('y[m]')
ax.plot(r[:,0], r[:,1])
fig.tight_layout()
save_fig("EarthSunVV")
plt.show()
!ec

You can easily generalize the calculation of the forces by defining a function
which takes in as input the various variables. We leave this as a challenge to you.




!split
===== Harmonic Oscillator =====

The harmonic oscillator is omnipresent in physics. Although you may think 
of this as being related to springs, it, or an equivalent
mathematical representation, appears in just about any problem where a
mode is sitting near its potential energy minimum. At that point,
$\partial_x V(x)=0$, and the first non-zero term (aside from a
constant) in the potential energy is that of a harmonic oscillator. In
a solid, sound modes (phonons) are built on a picture of coupled
harmonic oscillators, and in relativistic field theory the fundamental
interactions are also built on coupled oscillators positioned
infinitesimally close to one another in space. The phenomena of a
resonance of an oscillator driven at a fixed frequency plays out
repeatedly in atomic, nuclear and high-energy physics, when quantum
mechanically the evolution of a state oscillates according to
$e^{-iEt}$ and exciting discrete quantum states has very similar
mathematics as exciting discrete states of an oscillator.


!split
===== Harmonic Oscillator, deriving the Equations =====
The potential energy for a single particle as a function of its position $x$ can be written as a Taylor expansion about some point $x_0$

!bt
\begin{equation}
V(x)=V(x_0)+(x-x_0)\left.\partial_xV(x)\right|_{x_0}+\frac{1}{2}(x-x_0)^2\left.\partial_x^2V(x)\right|_{x_0}
+\frac{1}{3!}\left.\partial_x^3V(x)\right|_{x_0}+\cdots
\end{equation}
!et
If the position $x_0$ is at the minimum of the resonance, the first two non-zero terms of the potential are

!bt
\begin{eqnarray}
V(x)&\approx& V(x_0)+\frac{1}{2}(x-x_0)^2\left.\partial_x^2V(x)\right|_{x_0},\\
\nonumber
&=&V(x_0)+\frac{1}{2}k(x-x_0)^2,~~~~k\equiv \left.\partial_x^2V(x)\right|_{x_0},\\
\nonumber
F&=&-\partial_xV(x)=-k(x-x_0).
\end{eqnarray}
!et
Put into Newton's 2nd law (assuming $x_0=0$),

!bt
\begin{eqnarray}
m\ddot{x}&=&-kx,\\
x&=&A\cos(\omega_0 t-\phi),~~~\omega_0=\sqrt{k/m}.
\end{eqnarray}
!et

!split
===== Harmonic Oscillator, Technicalities =====

Here $A$ and $\phi$ are arbitrary. Equivalently, one could have
written this as $A\cos(\omega_0 t)+B\sin(\omega_0 t)$, or as the real
part of $Ae^{i\omega_0 t}$. In this last case $A$ could be an
arbitrary complex constant. Thus, there are 2 arbitrary constants
(either $A$ and $B$ or $A$ and $\phi$, or the real and imaginary part
of one complex constant. This is the expectation for a second order
differential equation, and also agrees with the physical expectation
that if you know a particle's initial velocity and position you should
be able to define its future motion, and that those two arbitrary
conditions should translate to two arbitrary constants.

A key feature of harmonic motion is that the system repeats itself
after a time $T=1/f$, where $f$ is the frequency, and $\omega=2\pi f$
is the angular frequency. The period of the motion is independent of
the amplitude. However, this independence is only exact when one can
neglect higher terms of the potential, $x^3, x^4\cdots$. Once can
neglect these terms for sufficiently small amplitudes, and for larger
amplitudes the motion is no longer purely sinusoidal, and even though
the motion repeats itself, the time for repeating the motion is no
longer independent of the amplitude.

One can also calculate the velocity and the kinetic energy as a function of time,

!bt
\begin{eqnarray}
\dot{x}&=&-\omega_0A\sin(\omega_0 t-\phi),\\
\nonumber
K&=&\frac{1}{2}m\dot{x}^2=\frac{m\omega_0^2A^2}{2}\sin^2(\omega_0t-\phi),\\
\nonumber
&=&\frac{k}{2}A^2\sin^2(\omega_0t-\phi).
\end{eqnarray}
!et

!split
===== Harmonic Oscillator, Total Energy =====

The total energy is then

!bt
\begin{equation}
E=K+V=\frac{1}{2}m\dot{x}^2+\frac{1}{2}kx^2=\frac{1}{2}kA^2.
\end{equation}
!et

The total energy then goes as the square of the amplitude.


A pendulum is an example of a harmonic oscillator. By expanding the
kinetic and potential energies for small angles find the frequency for
a pendulum of length $L$ with all the mass $m$ centered at the end by
writing the eq.s of motion in the form of a harmonic oscillator.

The potential energy and kinetic energies are (for $x$ being the displacement)

!bt
\begin{eqnarray*}
V&=&mgL(1-\cos\theta)\approx mgL\frac{x^2}{2L^2},\\
K&=&\frac{1}{2}mL^2\dot{\theta}^2\approx \frac{m}{2}\dot{x}^2.
\end{eqnarray*}
!et

For small $x$ Newton's 2nd law becomes

!bt
\[
m\ddot{x}=-\frac{mg}{L}x,
\]
!et

and the spring constant would appear to be $k=mg/L$, which makes the
frequency equal to $\omega_0=\sqrt{g/L}$. Note that the frequency is
independent of the mass.

!split
===== Additional Material: Link between Line Integrals and Conservative forces =====


The fundamental theorem of line integrals, also called the gradient theorem, states that
\begin{aligned} \int_a^b \nabla \blueE{f}(\greenE{\vec{\textbf{r}}}(t)) \cdot \redE{\vec{\textbf{r}}'}(t)dt = \blueE{f}(\greenE{\vec{\textbf{r}}}(b)) - \blueE{f}(\greenE{\vec{\textbf{r}}}(a)) \end{aligned} 
∫ 

 
The intuition behind this formula is that each side represents the change in the value of a multivariable function \blueE{f}fstart color #0c7f99, f, end color #0c7f99 as you walk along a path parameterized by \greenE{\vec{\textbf{r}}(t)} 
r
 (t)start color #0d923f, start bold text, r, end bold text, with, vector, on top, left parenthesis, t, right parenthesis, end color #0d923f.
This formula implies that gradient fields are path independent, meaning the line integrals along any two paths connecting the same start and end points will be equal.
Statement of the theorem
Recall that the fundamental theorem of calculus in the single-variable world states that
\begin{aligned} \int_a^b g'(t)dt = g(b) - g(a) \end{aligned} 
∫ 
a
b
​	
 g 
′
 (t)dt=g(b)−g(a)
​	
 
In some sense, this says that integration is the opposite of differentiation.
The fundamental theorem of line integrals, also known as the gradient theorem, is one of several ways to extend this theorem into higher dimensions. In a sense, it says that line integration through a vector field is the opposite of the gradient. The statement of the theorem is that
\begin{aligned} \int_a^b \nabla \blueE{f}(\greenE{\vec{\textbf{r}}}(t)) \cdot \redE{\vec{\textbf{r}}'}(t)dt = \blueE{f}(\greenE{\vec{\textbf{r}}}(b)) - \blueE{f}(\greenE{\vec{\textbf{r}}}(a)) \end{aligned} 
∫ 
a
b
​	
 ∇f( 
r
 (t))⋅ 
r
  
′
 (t)dt=f( 
r
 (b))−f( 
r
 (a))
​	
 

Where
\blueE{f}fstart color #0c7f99, f, end color #0c7f99 is some scalar-valued multivariable function.
\nabla \blueE{f}∇fdel, start color #0c7f99, f, end color #0c7f99 is the gradient of \blueE{f}fstart color #0c7f99, f, end color #0c7f99.
\greenE{\vec{\textbf{r}}}(t) 
r
 (t)start color #0d923f, start bold text, r, end bold text, with, vector, on top, end color #0d923f, left parenthesis, t, right parenthesis is a vector-valued function which parameterizes some path through the input space of \blueE{f}fstart color #0c7f99, f, end color #0c7f99.
\vec{\textbf{r}}(a) 
r
 (a)start bold text, r, end bold text, with, vector, on top, left parenthesis, a, right parenthesis and \vec{\textbf{r}}(b) 
r
 (b)start bold text, r, end bold text, with, vector, on top, left parenthesis, b, right parenthesis are the end points of the path.
\redE{\vec{\textbf{r}}'}(t) 
r
  
′
 (t)start color #bc2612, start bold text, r, end bold text, with, vector, on top, prime, end color #bc2612, left parenthesis, t, right parenthesis is the derivative of \greenE{\vec{\textbf{r}}}(t) 
r
 (t)start color #0d923f, start bold text, r, end bold text, with, vector, on top, end color #0d923f, left parenthesis, t, right parenthesis, taken component-wise as usual.
You might also see this theorem written without reference to the parameterization \vec{\textbf{r}}(t) 
r
 (t)start bold text, r, end bold text, with, vector, on top, left parenthesis, t, right parenthesis as follows:
\begin{aligned} \int_C \nabla f \cdot d\textbf{s} = f(B) - f(A) \end{aligned} 
∫ 
C
​	
 ∇f⋅ds=f(B)−f(A)
​	
 
Where CCC represents the path through space, with AAA as its starting point and BBB as its ending point, and d\textbf{s}dsd, start bold text, s, end bold text is thought of as a tiny step along CCC.
In short, the theorem states that the line integral of the gradient of a function fff gives the total change in the value of fff from the start of the curve to its end.
The intuition
The meaning behind this formula is actually fairly straightforward​, once we take some time to digest the meaning of each term. There are two main players on the stage right now:
A path wandering through space (let's say two-dimensional space, for now, to make drawing easier).
A function fff which takes in points of that path as its input, and outputs a number.
Think about how the value of the function fff changes as we walk along the path. The following video shows one way to visualize this, where the graph of some function fff is shown in blue, a path in the xyxyx, y-plane is shown in red, and the projection of that path onto the graph is also shown in red.



A quick proof
Using the multivariable chain rule, we have
\begin{aligned} \dfrac{d}{dt} f(\vec{\textbf{r}}(t)) = \nabla f(\vec{\textbf{r}}(t)) \cdot \vec{\textbf{r}}'(t) \end{aligned} 
dt
d
​	
 f( 
r
 (t))=∇f( 
r
 (t))⋅ 
r
  
′
 (t)
​	
 
Plugging this into the statement of the gradient theorem, we see it becomes the same as the fundamental theorem of calculus
\begin{aligned} &\phantom{=} \int_a^b \nabla f(\vec{\textbf{r}}(t)) \cdot \vec{\textbf{r}}'(t)dt \\\\ &= \int_a^b \dfrac{d}{dt} f(\vec{\textbf{r}}(t))dt \\\\ &= f(\vec{\textbf{r}}(b)) - f(\vec{\textbf{r}}(a)) \end{aligned} 
​	
  
=∫ 
a
b
​	
 ∇f( 
r
 (t))⋅ 
r
  
′
 (t)dt
=∫ 
a
b
​	
  
dt
d
​	
 f( 
r
 (t))dt
=f( 
r
 (b))−f( 
r
 (a))
​	
 
Tada!
This proof leverages the powerful fundamental theorem of calculus, along with the multivariable chain rule, and hence looks deceptively simple. A good exercise in understanding this theorem is to think through how exactly this quick and tidy three-line proof encapsulates the intuition for the gradient theorem spelled out in the last section.
There's nothing wrong with using other powerful theorems to help prove new results. In fact, to avoid doing so would be foolish. However, walking through such proofs is often not enough for a deeper understanding, so it's healthy to unravel new results into their full meaning, seeing how they stand up on their own.



Solution 2: Apply the fundamental theorem of line integrals
Applying the fundamental theorem of line integrals, we can skip over many of the steps from the previous solution, including the computation of the gradient of fff and the derivative of \vec{\textbf{r}}(t) 
r
 (t)start bold text, r, end bold text, with, vector, on top, left parenthesis, t, right parenthesis.
Solve the line integral above using the gradient theorem. [Solution]
If you look back through the full computation of the line integral in solution 1, the computations we performed actually feel pretty silly. We took the derivative of everything, including the partial derivatives of x^2 + y^2x 
2
 +y 
2
 x, squared, plus, y, squared and the ordinary derivatives of ttt and \sin(t)sin(t)sine, left parenthesis, t, right parenthesis, then later integrated those derivatives back up to where they started.
Working through this should also help build an intuition for how the fundamental theorem of line integrals derives from the fundamental theorem of calculus.
Path independence
The gradient theorem has a really important consequence regarding gradient fields. Suppose you have two distinct curves C_1C 
1
​	
 C, start subscript, 1, end subscript and C_2C 
2
​	
 C, start subscript, 2, end subscript, each connecting the same two points AAA and BBB. Let's say these are wandering through the gradient field of some scalar-valued function fff:

According to the gradient theorem, the line integral of \nabla f∇fdel, f along each of these curves will be the same, since that integral is completely determined by the value of fff at AAA and BBB:
\begin{aligned} \int_{C_1} \nabla f \cdot d\textbf{r} = f(B) - f(A) = \int_{C_2} \nabla f \cdot d\textbf{r} \end{aligned} 
∫ 
C 
1
​	
 
​	
 ∇f⋅dr=f(B)−f(A)=∫ 
C 
2
​	
 
​	
 ∇f⋅dr
​	
 
We explore this idea further in the next article on conservative vector fields.
Summary
The fundamental theorem of line integrals, also called the gradient theorem, states that
\begin{aligned} \int_a^b \nabla \blueE{f}(\greenE{\vec{\textbf{r}}}(t)) \cdot \redE{\vec{\textbf{r}}'}(t)dt = \blueE{f}(\greenE{\vec{\textbf{r}}}(b)) - \blueE{f}(\greenE{\vec{\textbf{r}}}(a)) \end{aligned} 
∫ 
a
b
​	
 ∇f( 
r
 (t))⋅ 
r
  
′
 (t)dt=f( 
r
 (b))−f( 
r
 (a))
​	
 
The intuition behind this formula is that each side represents the change in the value of a multivariable function \blueE{f}fstart color #0c7f99, f, end color #0c7f99 as you walk along a path parameterized by \greenE{\vec{\textbf{r}}(t)} 
r
 (t)start color #0d923f, start bold text, r, end bold text, with, vector, on top, left parenthesis, t, right parenthesis, end color #0d923f.
This formula implies that gradient fields are path independent, meaning the line integrals along any two paths connecting the same start and end points will be equal.


A vector field \textbf{F}(x, y)F(x,y)start bold text, F, end bold text, left parenthesis, x, comma, y, right parenthesis is called a conservative vector field if it satisfies any one of the following three properties (all of which are defined within the article):
Line integrals of \textbf{F}Fstart bold text, F, end bold text are path independent.
Line integrals of \textbf{F}Fstart bold text, F, end bold text over closed loops are always 000.
\textbf{F}Fstart bold text, F, end bold text is the gradient of some scalar-valued function, i.e. \textbf{F} = \nabla gF=∇gstart bold text, F, end bold text, equals, del, g for some function ggg.
There is also another property equivalent to all these: \textbf{F}Fstart bold text, F, end bold text is irrotational, meaning its curl is zero everywhere (with a slight caveat). However, I'll discuss that in a separate article which defines curl in terms of line integrals.
The key takeaway here is not just the definition of a conservative vector field, but the surprising fact that the seemingly different conditions listed above are equivalent to each other. Madness!
Path independence
Imagine you have any ol' off-the-shelf vector field \textbf{F}(x, y)F(x,y)start bold text, F, end bold text, left parenthesis, x, comma, y, right parenthesis, and you consider the line integrals of \textbf{F}Fstart bold text, F, end bold text of two separate paths, C_1C 
1
​	
 C, start subscript, 1, end subscript and C_2C 
2
​	
 C, start subscript, 2, end subscript, each starting at a point AAA and ending at a point BBB

For almost all vector fields \textbf{F}Fstart bold text, F, end bold text, and almost all choices for the two paths C_1C 
1
​	
 C, start subscript, 1, end subscript and C_2C 
2
​	
 C, start subscript, 2, end subscript, these integrals will be different.
\begin{aligned} \int_{C_1} \textbf{F} \cdot d\textbf{s} \ne \int_{C_2} \textbf{F} \cdot d\textbf{s} \quad \leftarrow \text{Almost always true} \end{aligned} 
∫ 
C 
1
​	
 
​	
 F⋅ds 

​	
 =∫ 
C 
2
​	
 
​	
 F⋅ds←Almost always true
​	
 
And this makes sense! Each integral is adding up completely different values at completely different points in space. What's surprising is that there exist some vector fields where distinct paths connecting the same two points will always be equal, no matter the choice of paths (of which there are super-infinitely many).
In the last article, covering the gradient theorem we saw that in the special case of vector fields which are the gradient of some scalar-valued function, \nabla f∇fdel, f, this magical property is true. The line integrals along distinct paths connecting the same two points AAA and BBB will always evaluate to the same thing:
\begin{aligned} \int_{C_1} \nabla f \cdot d\textbf{s} = \underbrace{ f(B) - f(A) }_{\substack{ \text{Result of the} \\\\ \text{gradient theorem} }} = \int_{C_2} \nabla f \cdot d\textbf{s} \end{aligned} 
∫ 
C 
1
​	
 
​	
 ∇f⋅ds= 
Result of the
gradient theorem
​	
 
f(B)−f(A)
​	
 
​	
 =∫ 
C 
2
​	
 
​	
 ∇f⋅ds
​	
 
Definition: This property is called path independence. Specifically, a line integral through a vector field \textbf{F}(x, y)F(x,y)start bold text, F, end bold text, left parenthesis, x, comma, y, right parenthesis is said to be path independent if the value of the integral only depends on the point where the path starts and the point where it ends, not the specific choice of path in between.
Actually, when you properly understand the gradient theorem, this statement isn't totally magical. This is because line integrals against the gradient of fff measure the change in the value of fff. Visualizing this with the graph of fff, this says that any two paths bringing you from one point to another change your altitude by the same amount.
Khan Academy video wrapper
The takeaway from this result is that gradient fields are very special vector fields. Because this property of path independence is so rare, in a sense, "most" vector fields cannot be gradient fields.
Path independence implies gradient field
Okay, so gradient fields are special due to this path independence property. But can you come up with a vector field \textbf{F}(x, y)F(x,y)start bold text, F, end bold text, left parenthesis, x, comma, y, right parenthesis in which all line integrals are path independent, but which is not the gradient of some scalar-valued function?
I guess I've spoiled the answer with the section title and the introduction: All vector fields in which line integrals are path independent must be the gradient of some function. By why?
Really, why would this be true? Consider an arbitrary vector field \textbf{F}(x, y)F(x,y)start bold text, F, end bold text, left parenthesis, x, comma, y, right parenthesis in which line integrals are path independent, meaning
\begin{aligned} \int_{C_1} \textbf{F} \cdot d\textbf{s} = \int_{C_2} \textbf{F} \cdot d\textbf{s} \end{aligned} 
∫ 
C 
1
​	
 
​	
 F⋅ds=∫ 
C 
2
​	
 
​	
 F⋅ds
​	
 
for all paths C_1C 
1
​	
 C, start subscript, 1, end subscript and C_2C 
2
​	
 C, start subscript, 2, end subscript which connect the same two points AAA and BBB. What is it about this property that ensures the existence of some function ggg such that \nabla g = \textbf{F}∇g=Fdel, g, equals, start bold text, F, end bold text?
Challenge question: Can you think of a way to construct such a function ggg in terms of \textbf{F}Fstart bold text, F, end bold text using the fact that \textbf{F}Fstart bold text, F, end bold text is path-independent?
This is a tricky question, but it might help to look back at the gradient theorem for inspiration.
[Answer]
Closed loops
Definition: A path is called closed if it starts and ends at the same point. Such paths are also commonly called closed loops.
For example, the path CCC pictured below starts and ends at AAA.

If we take a vector field \textbf{F}Fstart bold text, F, end bold text where all line integrals are path independent, the line integral of \textbf{F}Fstart bold text, F, end bold text on any closed loop will be 000. Why?
[Answer] [Another answer]
The converse of this fact is also true: If the line integrals of \textbf{F}Fstart bold text, F, end bold text on all closed loops evaluate to 000, then all line integrals must be path independent. Why?
[Answer]
Funky notation for closed-loop integrals.
You will sometimes see a line integral over a closed loop CCC written as
\begin{aligned} \oint_C \textbf{F} \cdot d\textbf{r} \end{aligned} 
∮ 
C
​	
 F⋅dr
​	
 
Don't worry, this is not a new operation that needs to be learned. It is just a line integral, computed in just the same way as we have done before, but it is meant to emphasize to the reader that CCC is a closed loop.
Potential energy
In the article introducing​ line integrals through a vector field, I mentioned briefly how in physics, the work done by a force on an object in motion is computed by taking a line integral of the force's vector field along the path of motion.
\begin{aligned} W = \int_C \textbf{F} \cdot d\textbf{s} \end{aligned} 
W=∫ 
C
​	
 F⋅ds
​	
 
A force is called conservative if the work it does on an object moving from any point AAA to another point BBB is always the same, no matter what path is taken. In other words, if this integral is always path-independent. Fundamental forces like gravity and the electric force are conservative, and the quintessential example of a non-conservative force is friction.
This has an interesting consequence based on our discussion above: If a force is conservative, it must be the gradient of some function.
\textbf{F} = \nabla UF=∇Ustart bold text, F, end bold text, equals, del, U
Moreover, according to the gradient theorem, the work done on an object by this force as it moves from point AAA to point BBB can be computed just by evaluating this function UUU at each point:
\begin{aligned} W &= \int_C \textbf{F} \cdot d\textbf{s} \\\\ &= \int_C \nabla U \cdot d\textbf{s} \\\\ &= U(B) - U(A) \end{aligned} 
W
​	
  
=∫ 
C
​	
 F⋅ds
=∫ 
C
​	
 ∇U⋅ds
=U(B)−U(A)
​	
 
As the physics students among you have likely guessed, this function UUU is potential energy. For example, if you take the gradient of gravitational potential or electric potential, you will get the gravitational force or electric force respectively. This is why computing the work done by a conservative force can be simplified to comparing potential energies.
It also means you could never have a "potential friction energy" since friction force is non-conservative.
Escher
Moving from physics to art, this classic drawing "Ascending and Descending" by M.C. Escher shows what the world would look like if gravity were a non-conservative force.

Closed loop perspective:
Imagine walking clockwise on this staircase. With each step gravity would be doing negative work on you. So integrating the work along your full circular loop, the total work gravity does on you would be quite negative. However, that's an integral in a closed loop, so the fact that it's nonzero must mean the force acting on you cannot be conservative.
Path independence perspective
Imagine walking from the tower on the right corner to the left corner. If you get there along the clockwise path, gravity does negative work on you. If you get there along the counterclockwise path, gravity does positive work on you. Since both paths start and end at the same point, path independence fails, so the gravity force field cannot be conservative.
Gradient perspective:
In the real world, gravitational potential corresponds with altitude​, because the work done by gravity is proportional to a change in height. What makes the Escher drawing striking is that the idea of altitude doesn't make sense. Many steps "up" with no steps down can lead you back to the same point. This corresponds with the fact that there is no potential function UUU such that \nabla U∇Udel, U give the gravity field.
